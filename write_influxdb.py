# Schema for utility data
# Bucket: utilities
# Measurement: energy_watthour, water_cuft, energy_watthour
# Tag Key: unit
# Tag value: "Wh", "CuFt"
# Field Key: "solar_energy_daily", "water_meter_reading", "water_consumption", "electricity_usage"

from datetime import datetime, time
import pytz
import argparse

from influxdb_client import InfluxDBClient, Point, WritePrecision
from influxdb_client.client.write_api import SYNCHRONOUS, PointSettings
from influxdb_client.client.write.dataframe_serializer import data_frame_to_list_of_points
 
import pandas

url = "http://192.168.88.12:8086"
token = "pc5XzRSoA7b_CKgpl6yiyxCiLmEo-Y36l8jRMKXTkNxDNPU3jiQIgBk5ZtIXU3WUPYhzqMgNaPW8tif02O0OfA=="
org = "wolverines"

bucket = "utilities" # "investments"

def read_enphase_daily_report(filename):
    """Read the daily report generated by enphase and output a line protocol list"""
    
    df = pandas.read_csv(filename)

    # drop last row with the total
    df = df.drop(df.index[-1:])
   
    # sanitize the date/time to day level
    # day = [line.split()[0] for line in df["Date/Time"]]
    date = [datetime.fromisoformat(line.split()[0]) for line in df["Date/Time"]]
    
    df = df.rename(columns={"Energy Discharged (Wh)": "solar_daily_production"}) 
    df = df.assign(time=date)
    df = df.drop(columns=["Date/Time"])
    
    # a tag column "source" = enphase and "source"=pepco
    # add a column with units (tags)
    df = df.assign(units="Wh")
    df = df.assign(source="enphase")
    df = df.set_index("time")

    return df

def read_pepco(filename):
    """Read pepco greenbutton data file and parse into Pandas dataframe"""

    eastern = pytz.timezone("America/New_York")
    utc = pytz.utc
    
    # remove first 5 lines
    df = pandas.read_csv(filename, header=4)
    df = df.drop(columns=["TYPE", "COST"])

    data_date = [datetime.fromisoformat(line) for line in df["DATE"]]
    data_time = [time(int(t.split(":")[0]), int(t.split(":")[1])) for t in df["END TIME"]]

    dt = [datetime.combine(d, t) for d,t in zip(data_date, data_time)]
    dt = [eastern.localize(d).astimezone(utc) for d in dt] # utc time now
   
    df = df.assign(time=dt)
    df["USAGE"] = df["USAGE"] * 1000
    df = df.rename(columns={"USAGE": "energy_consumption", "UNITS": "units"})
    df = df.drop(columns=["DATE", "START TIME", "END TIME"])
    df = df.assign(units="Wh")
    df = df.assign(source="pepco")
    df = df.set_index("time")
    
    return df

def read_dcwater(filename):
    """Read DC Water usage and parse into Pandas dataframe"""
    
    df = pandas.read_csv(filename, index_col=False)
    
    eastern = pytz.timezone("America/New_York")
    utc = pytz.utc

    dt = [datetime.strptime(d, "%m/%d/%Y %H:%M:%S %p") for d in df["Reading Time"]]
    dt = [eastern.localize(d).astimezone(utc) for d in dt] # utc time now

    df = df.assign(time=dt)
    df = df.drop(columns=["Reading Time", " Units"])
    df = df.rename(columns={"Meter Reading": "water_meter", "Consumption": "water_consumption"})
    df = df.assign(units="CuFt")
    df = df.assign(source="dcwater")    
    df = df.set_index("time")

    return df


def ingest_dataframe(df, measurement_name, tag_columns):
    """Write data"""

    point_settings = PointSettings()
    point_settings.add_default_tag("units", "Wh")
    point_settings.add_default_tag("source", "enphase")

    points = data_frame_to_list_of_points(data_frame=df,
                                          point_settings=point_settings, 
                                          data_frame_measurement_name=measurement_name,
                                          data_frame_tag_columns=tag_columns)
    
    client = InfluxDBClient(url=url, token=token, org=org)
    write_api = client.write_api()

    # line protocol: measurementName,tagKey=tagValue fieldKey="fieldValue" timestamp
    # write_api.write(bucket=bucket, org=org, record=df, 
    #                 data_frame_measurement_name=measurement_name,
    #                 data_frame_tag_columns=tag_columns)
    write_api.write(bucket=bucket, org=org, record=points)

    write_api.close()
    client.close()

# only write new data that doesn't exists in the database already
if __name__ == "__main__":

    # setup argparse
    parser = argparse.ArgumentParser(description="Write utility data to influxdb")

    parser.add_argument("solar", metavar="S", type=str, help="Solar production CSV file")
    parser.add_argument("power", metavar="P", type=str, help="Power production CSV file")
    parser.add_argument("water", metavar="W", type=str, help="Water production CSV file")

    args = parser.parse_args()

    df = read_enphase_daily_report(args.solar)
    ingest_dataframe(df, measurement_name="solar_daily_production", tag_columns=["units", "source"])

    df = read_pepco(args.power)
    ingest_dataframe(df, measurement_name="energy_consumption", tag_columns=["units", "source"])

    df = read_dcwater(args.water)
    ingest_dataframe(df, measurement_name="water_consumption", tag_columns=["units", "source"])

